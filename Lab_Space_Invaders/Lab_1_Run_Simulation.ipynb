{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "from gymnasium . wrappers . frame_stack import FrameStack\n",
    "from gymnasium . wrappers . atari_preprocessing import AtariPreprocessing\n",
    "\n",
    "gym . register_envs ( ale_py )\n",
    "\n",
    "model_file = \"< path_to_your_model_here >\"\n",
    "agent = keras . models . load_model ( model_file )\n",
    "\n",
    "env = gym . make (\" SpaceInvadersNoFrameskip -v4\", render_mode =\" human \")\n",
    "env = AtariPreprocessing ( env )\n",
    "env = FrameStack (env , 4)\n",
    "\n",
    "state , _ = env . reset ()\n",
    "done = False\n",
    "while not done :\n",
    "# first convert to a tensor for compute efficiency\n",
    "state_tensor = keras . ops . convert_to_tensor ( state )\n",
    "# shape of state is 4, 84, 84, but we need 84, 84, 4\n",
    "state_tensor = keras . ops . transpose ( state_tensor , [1, 2, 0])\n",
    "# Add batch dimension\n",
    "state_tensor = keras . ops . expand_dims ( state_tensor , 0)\n",
    "# ’predict ’ method is for large batches , call as function instead\n",
    "action_probs = agent ( state_tensor , training = False )\n",
    "# Take ’best ’ action\n",
    "action = keras .ops . argmax ( action_probs [0]) . numpy ()\n",
    "state , reward , done , _, _ = env . step ( action )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
