{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labrapport Reinforcement Learning Space Invaders\n",
    "- Förklaring av modellen och Deep Learning (Q_learning):\n",
    "- Genomförande: Jag gjorde laborationen både på min lokala dator och på Google Colab, simultant.  \n",
    "- Loggning av resultaten skedde hela tiden, mestadels \"manuellt\".\n",
    "- Google Colab: Jag betalade för att använda snabbare runtimes, totalt 200 calculation credits. Provade med lite olika inställningar för max_memory_length (1000k, 10k, 250k), körde mest på 250k. Svårt att utvärdera vad som blev bäst. I Google Colab hade jag problem med flera saker:\n",
    "1. Efter att ha kört i några timmar kom en captcha och frågade om jag var en robot. Ibland missade jag att svara på den och då slutade inlärningsprocessen.\n",
    "2. Den gjorde timeout efter ett tag, pga inaktivitet. Det gick alltså inte att låta den bara jobba på tills beräknings krediterna var slut. Den längsta sammanhängande inlärningen var strax under 8h.\n",
    "Omstart: varje gång som inlärningen avbröts, så laddade jag in den senaste .keras filen inför nästa omgång träning. Jag gjorde ett försök  att spara listorna med data som används i inlärningsprocessen. Det gick bra att spara dem, men de tog stor plats. Två av listorna blev 3GB+ vardera, och min Google Drive fick minnesproblem. Dessutom fick jag det inte att fungera med att använda de sparade listorna i alla fall. Detta innebär att vid varje ny start av en inlärning, så fick den börja om med att lära sig och fylla i listorna igen, oklart hur det påverkade inlärningsprocessen.\n",
    "\n",
    "## Resultat:\n",
    "### Lokalt:\n",
    "- Lät den träna mellan 5 december till 15 december utan avbrott.  \n",
    "- 1310000 frames  \n",
    "- 2237 episodes  \n",
    "##### Observationer:\n",
    "- I början av laborationen så tog varje 10k frames bara 5-10 minuter. Efter ett tag så tog 10k frames över tre timmar, vilket kanske kan bero på att jag använde max_memory_length = 1000000 (?).  \n",
    "- Träningen gick långsamt och det var inte tydligt att det blev bättre och bättre. Snarare verkade det som att modellen bitvis blev bättre men sedan sämre igen, i ett cyklande mönster.\n",
    "#### Lokala Inställningar:\n",
    "```\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 1.0\n",
    "epsilon_interval = (\n",
    "    epsilon_max - epsilon_min\n",
    ")\n",
    "batch_size=32\n",
    "max_episodes = 10000 # maximum episodes to run\n",
    "max_frames = 1e7 # max frames to run\n",
    "epsilon_random_frames = 50000 # Number of frames to take random action and observe output\n",
    "epsilon_greedy_frames = 1000000.0 # Number of frames for exploration\n",
    "max_memory_length = 1000000 # Maximum replay length\n",
    "\n",
    "max_steps_per_episode = 10000\n",
    "update_after_actions = 4 # Train the model after 4 actions\n",
    "update_target_network = 10000 # How often to update the target network\n",
    "loss_function = keras.losses.Huber() # Using huber loss for stability\n",
    "```\n",
    "Video: sparade var 50:e träningssession som video\n",
    "\n",
    "### Google Colab:\n",
    "- Lät den träna mellan 10 december till 15 december. Det var flertalet avbrott, minst 10-14 stycken. Efter varje avbrott så läste jag in den senast sparade .keras modellen, att anväda som start till nästa träningsomgång.\n",
    "- Provade olika \n",
    "- 4.9M frames\n",
    "- 7700+ episodes\n",
    "#### Google Colab inställningar:\n",
    "```\n",
    "gamma = 0.99\n",
    "epsilon = 0.1\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.1\n",
    "epsilon_interval = (\n",
    "    epsilon_max - epsilon_min\n",
    ")\n",
    "batch_size = 32\n",
    "max_episodes = 10000 # maximum episodes to run\n",
    "max_frames = 1e7 # max frames to run\n",
    "epsilon_random_frames = 0 # eftersom jag läst in redan tränade modeller, så ville jag ha 0 random\n",
    "epsilon_greedy_frames = 1000000.0 # Number of frames for exploration\n",
    "max_memory_length = 250000 # 250k mestadels men även 10k\n",
    "\n",
    "max_steps_per_episode = 10000\n",
    "update_after_actions = 4 # Train the model after 4 actions\n",
    "update_target_network = 10000 # How often to update the target network\n",
    "loss_function = keras.losses.Huber() # Using huber loss for stability\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = pd.read_csv('spaceinvader_colab.csv')\n",
    "local = pd.read_csv('spaceinvader_local.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
